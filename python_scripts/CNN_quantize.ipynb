{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 6, 6, 8)           80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 8)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 72)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                730       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 810\n",
      "Trainable params: 810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(r'C:\\Users\\srico\\Documents\\BEARHW\\Image Classification CNN\\models\\model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that will return outputs of all intermediate layers\n",
    "layer_outputs = [layer.output for layer in model.layers]  # List of intermediate layer outputs\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example input data, assuming the input shape is (1, 8, 8, 1)\n",
    "input_data = np.array([\n",
    "    0.0, 0.0, 0.3125, 0.8125, 0.5625, 0.0625, 0.0, 0.0, 0.0, 0.0, \n",
    "    0.8125, 0.9375, 0.625, 0.9375, 0.3125, 0.0, 0.0, 0.1875, 0.9375, 0.125, \n",
    "    0.0, 0.6875, 0.5, 0.0, 0.0, 0.25, 0.75, 0.0, 0.0, 0.5, \n",
    "    0.5, 0.0, 0.0, 0.3125, 0.5, 0.0, 0.0, 0.5625, 0.5, 0.0, \n",
    "    0.0, 0.25, 0.6875, 0.0, 0.0625, 0.75, 0.4375, 0.0, 0.0, 0.125, \n",
    "    0.875, 0.3125, 0.625, 0.75, 0.0, 0.0, 0.0, 0.0, 0.375, 0.8125, \n",
    "    0.625, 0.0, 0.0, 0.0,\n",
    "]).reshape(1, 8, 8, 1).astype(np.float32)\n",
    "\n",
    "# Get the intermediate layer outputs\n",
    "intermediate_outputs = intermediate_model(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of layer conv2d: [[[[0.95353466 0.         1.2029399  0.         1.8446589  1.1326841\n",
      "    0.         0.        ]\n",
      "   [2.8136399  0.         2.3423574  0.16445473 2.1892896  1.1388681\n",
      "    0.3176513  0.        ]\n",
      "   [2.8030372  0.32161674 3.0093622  1.7498195  0.7465464  0.\n",
      "    2.235262   0.24579245]\n",
      "   [2.2858536  0.         2.6526148  1.4764743  1.0869063  0.\n",
      "    1.8631382  0.5413518 ]\n",
      "   [2.562481   0.         1.3750668  0.08665054 1.4874164  0.31211796\n",
      "    0.9906652  0.        ]\n",
      "   [1.424877   0.2536646  0.51710474 0.         1.0113033  0.\n",
      "    1.3396316  0.        ]]\n",
      "\n",
      "  [[1.2898009  0.15609658 1.7212894  0.11982755 2.0384324  1.4549541\n",
      "    0.         0.09343165]\n",
      "   [2.94999    0.42540526 2.2453415  1.3307467  1.0062621  0.26704496\n",
      "    1.212928   0.        ]\n",
      "   [1.6978055  1.6796619  1.8259594  2.529538   0.14350866 0.\n",
      "    2.6904998  1.3513912 ]\n",
      "   [1.3461654  1.1247172  2.0690184  2.015191   1.0559984  0.28435263\n",
      "    1.1525468  1.7042546 ]\n",
      "   [2.7027938  0.         2.3156664  1.1070583  0.99280083 0.\n",
      "    1.1953782  0.10509598]\n",
      "   [1.9547784  0.23752439 0.9331134  0.82389224 0.71929586 0.\n",
      "    1.7029228  0.31870332]]\n",
      "\n",
      "  [[1.4257793  0.4513042  1.7674303  0.59433514 1.6965027  1.228199\n",
      "    0.16945419 0.37060842]\n",
      "   [2.4187784  0.1236949  1.7127082  1.076311   0.23661943 0.\n",
      "    1.4391536  0.        ]\n",
      "   [0.65207976 0.9022164  0.4110334  1.1160265  0.26350033 0.\n",
      "    1.5541534  1.1043143 ]\n",
      "   [0.5559966  0.72535634 1.0178732  0.4961503  1.2030045  1.1499256\n",
      "    0.06591153 0.6172418 ]\n",
      "   [2.248695   0.         1.9589733  0.54925025 1.3170286  0.42048773\n",
      "    0.6695748  0.        ]\n",
      "   [2.0182574  0.3669911  1.0803102  0.71902645 0.61417043 0.\n",
      "    1.6078976  0.05753887]]\n",
      "\n",
      "  [[1.4670045  0.3419612  1.5730176  0.45367536 1.4626901  1.0172315\n",
      "    0.29547766 0.02505821]\n",
      "   [2.1670215  0.1009014  1.1955346  0.63377416 0.56039095 0.\n",
      "    1.2785586  0.        ]\n",
      "   [0.5402854  1.067823   0.24099055 0.51690686 0.44250166 0.\n",
      "    1.2001575  0.64288104]\n",
      "   [0.67791456 0.3882001  1.0132692  0.0396298  1.4112895  1.1319513\n",
      "    0.         0.10924378]\n",
      "   [2.3778474  0.         1.7698317  0.14933793 1.6331465  0.5970502\n",
      "    0.5158163  0.        ]\n",
      "   [1.9914138  0.4832557  1.1357808  0.5958575  0.61007863 0.\n",
      "    1.6883267  0.        ]]\n",
      "\n",
      "  [[1.4009293  0.03708458 1.722402   0.25890827 1.4702137  0.9246707\n",
      "    0.30977324 0.        ]\n",
      "   [2.5209918  0.         1.0968951  0.02379328 1.1350952  0.\n",
      "    0.9923849  0.        ]\n",
      "   [1.2787329  0.73768395 0.46386743 0.         1.4670259  0.\n",
      "    1.440725   0.        ]\n",
      "   [1.5776079  0.30453697 1.2401893  0.         2.4292855  1.1060576\n",
      "    0.12876487 0.        ]\n",
      "   [2.627414   0.2966296  1.9299456  0.23733476 1.3769342  0.43494686\n",
      "    0.912161   0.        ]\n",
      "   [1.4838119  0.64675385 1.227362   1.2213743  0.06612051 0.\n",
      "    1.9138644  0.4275521 ]]\n",
      "\n",
      "  [[0.88758194 0.44070745 1.7543807  0.82657254 1.1539837  1.1097537\n",
      "    0.15049565 0.7823876 ]\n",
      "   [2.5824099  0.         1.969483   0.35735685 0.9445674  0.12948692\n",
      "    0.9773809  0.        ]\n",
      "   [2.312974   0.         1.2711874  0.         2.3331387  0.04373974\n",
      "    1.3515471  0.        ]\n",
      "   [2.216756   0.43154693 1.892205   0.03612697 1.9640433  1.0143206\n",
      "    0.74413013 0.        ]\n",
      "   [1.9549506  0.63709277 1.9435309  1.6696192  0.         0.\n",
      "    1.8035527  0.29440305]\n",
      "   [0.6772367  0.53653395 0.6653875  1.7039522  0.         0.\n",
      "    1.4960648  1.4405928 ]]]]\n",
      "Output of layer max_pooling2d: [[[[2.94999    0.42540526 2.3423574  1.3307467  2.1892896  1.4549541\n",
      "    1.212928   0.09343165]\n",
      "   [2.8030372  1.6796619  3.0093622  2.529538   1.0869063  0.28435263\n",
      "    2.6904998  1.7042546 ]\n",
      "   [2.7027938  0.2536646  2.3156664  1.1070583  1.4874164  0.31211796\n",
      "    1.7029228  0.31870332]]\n",
      "\n",
      "  [[2.4187784  0.4513042  1.7674303  1.076311   1.6965027  1.228199\n",
      "    1.4391536  0.37060842]\n",
      "   [0.67791456 1.067823   1.0178732  1.1160265  1.4112895  1.1499256\n",
      "    1.5541534  1.1043143 ]\n",
      "   [2.3778474  0.4832557  1.9589733  0.71902645 1.6331465  0.5970502\n",
      "    1.6883267  0.05753887]]\n",
      "\n",
      "  [[2.5824099  0.44070745 1.969483   0.82657254 1.4702137  1.1097537\n",
      "    0.9923849  0.7823876 ]\n",
      "   [2.312974   0.73768395 1.892205   0.03612697 2.4292855  1.1060576\n",
      "    1.440725   0.        ]\n",
      "   [2.627414   0.64675385 1.9435309  1.7039522  1.3769342  0.43494686\n",
      "    1.9138644  1.4405928 ]]]]\n",
      "Output of layer flatten: [[2.94999    0.42540526 2.3423574  1.3307467  2.1892896  1.4549541\n",
      "  1.212928   0.09343165 2.8030372  1.6796619  3.0093622  2.529538\n",
      "  1.0869063  0.28435263 2.6904998  1.7042546  2.7027938  0.2536646\n",
      "  2.3156664  1.1070583  1.4874164  0.31211796 1.7029228  0.31870332\n",
      "  2.4187784  0.4513042  1.7674303  1.076311   1.6965027  1.228199\n",
      "  1.4391536  0.37060842 0.67791456 1.067823   1.0178732  1.1160265\n",
      "  1.4112895  1.1499256  1.5541534  1.1043143  2.3778474  0.4832557\n",
      "  1.9589733  0.71902645 1.6331465  0.5970502  1.6883267  0.05753887\n",
      "  2.5824099  0.44070745 1.969483   0.82657254 1.4702137  1.1097537\n",
      "  0.9923849  0.7823876  2.312974   0.73768395 1.892205   0.03612697\n",
      "  2.4292855  1.1060576  1.440725   0.         2.627414   0.64675385\n",
      "  1.9435309  1.7039522  1.3769342  0.43494686 1.9138644  1.4405928 ]]\n",
      "Output of layer dense: [[  3.8149195 -14.640079   -7.4657145  -5.1029096 -10.979712   -2.896831\n",
      "   -6.966517   -5.435467   -7.567821   -7.441173 ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the outputs of each layer\n",
    "for layer, output in zip(model.layers, intermediate_outputs):\n",
    "    print(f\"Output of layer {layer.name}: {output.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 6, 6, 8)           80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 8)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 72)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                730       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 810\n",
      "Trainable params: 810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intermediate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 6, 6, 8)           80        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract the output of the convolutional layer\n",
    "conv_layer_output = model.get_layer('conv2d').output\n",
    "\n",
    "# Create a new model that takes the same input but outputs only the convolutional layer's output\n",
    "conv_model = tf.keras.Model(inputs=model.input, outputs=conv_layer_output)\n",
    "\n",
    "# Print the summary of the new convolutional layer model\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the convolutional layer: [[[[0.95353466 0.         1.2029399  0.         1.8446589  1.1326841\n",
      "    0.         0.        ]\n",
      "   [2.8136399  0.         2.3423574  0.16445473 2.1892896  1.1388681\n",
      "    0.3176513  0.        ]\n",
      "   [2.8030372  0.32161674 3.0093622  1.7498195  0.7465464  0.\n",
      "    2.235262   0.24579245]\n",
      "   [2.2858536  0.         2.6526148  1.4764743  1.0869063  0.\n",
      "    1.8631382  0.5413518 ]\n",
      "   [2.562481   0.         1.3750668  0.08665054 1.4874164  0.31211796\n",
      "    0.9906652  0.        ]\n",
      "   [1.424877   0.2536646  0.51710474 0.         1.0113033  0.\n",
      "    1.3396316  0.        ]]\n",
      "\n",
      "  [[1.2898009  0.15609658 1.7212894  0.11982755 2.0384324  1.4549541\n",
      "    0.         0.09343165]\n",
      "   [2.94999    0.42540526 2.2453415  1.3307467  1.0062621  0.26704496\n",
      "    1.212928   0.        ]\n",
      "   [1.6978055  1.6796619  1.8259594  2.529538   0.14350866 0.\n",
      "    2.6904998  1.3513912 ]\n",
      "   [1.3461654  1.1247172  2.0690184  2.015191   1.0559984  0.28435263\n",
      "    1.1525468  1.7042546 ]\n",
      "   [2.7027938  0.         2.3156664  1.1070583  0.99280083 0.\n",
      "    1.1953782  0.10509598]\n",
      "   [1.9547784  0.23752439 0.9331134  0.82389224 0.71929586 0.\n",
      "    1.7029228  0.31870332]]\n",
      "\n",
      "  [[1.4257793  0.4513042  1.7674303  0.59433514 1.6965027  1.228199\n",
      "    0.16945419 0.37060842]\n",
      "   [2.4187784  0.1236949  1.7127082  1.076311   0.23661943 0.\n",
      "    1.4391536  0.        ]\n",
      "   [0.65207976 0.9022164  0.4110334  1.1160265  0.26350033 0.\n",
      "    1.5541534  1.1043143 ]\n",
      "   [0.5559966  0.72535634 1.0178732  0.4961503  1.2030045  1.1499256\n",
      "    0.06591153 0.6172418 ]\n",
      "   [2.248695   0.         1.9589733  0.54925025 1.3170286  0.42048773\n",
      "    0.6695748  0.        ]\n",
      "   [2.0182574  0.3669911  1.0803102  0.71902645 0.61417043 0.\n",
      "    1.6078976  0.05753887]]\n",
      "\n",
      "  [[1.4670045  0.3419612  1.5730176  0.45367536 1.4626901  1.0172315\n",
      "    0.29547766 0.02505821]\n",
      "   [2.1670215  0.1009014  1.1955346  0.63377416 0.56039095 0.\n",
      "    1.2785586  0.        ]\n",
      "   [0.5402854  1.067823   0.24099055 0.51690686 0.44250166 0.\n",
      "    1.2001575  0.64288104]\n",
      "   [0.67791456 0.3882001  1.0132692  0.0396298  1.4112895  1.1319513\n",
      "    0.         0.10924378]\n",
      "   [2.3778474  0.         1.7698317  0.14933793 1.6331465  0.5970502\n",
      "    0.5158163  0.        ]\n",
      "   [1.9914138  0.4832557  1.1357808  0.5958575  0.61007863 0.\n",
      "    1.6883267  0.        ]]\n",
      "\n",
      "  [[1.4009293  0.03708458 1.722402   0.25890827 1.4702137  0.9246707\n",
      "    0.30977324 0.        ]\n",
      "   [2.5209918  0.         1.0968951  0.02379328 1.1350952  0.\n",
      "    0.9923849  0.        ]\n",
      "   [1.2787329  0.73768395 0.46386743 0.         1.4670259  0.\n",
      "    1.440725   0.        ]\n",
      "   [1.5776079  0.30453697 1.2401893  0.         2.4292855  1.1060576\n",
      "    0.12876487 0.        ]\n",
      "   [2.627414   0.2966296  1.9299456  0.23733476 1.3769342  0.43494686\n",
      "    0.912161   0.        ]\n",
      "   [1.4838119  0.64675385 1.227362   1.2213743  0.06612051 0.\n",
      "    1.9138644  0.4275521 ]]\n",
      "\n",
      "  [[0.88758194 0.44070745 1.7543807  0.82657254 1.1539837  1.1097537\n",
      "    0.15049565 0.7823876 ]\n",
      "   [2.5824099  0.         1.969483   0.35735685 0.9445674  0.12948692\n",
      "    0.9773809  0.        ]\n",
      "   [2.312974   0.         1.2711874  0.         2.3331387  0.04373974\n",
      "    1.3515471  0.        ]\n",
      "   [2.216756   0.43154693 1.892205   0.03612697 1.9640433  1.0143206\n",
      "    0.74413013 0.        ]\n",
      "   [1.9549506  0.63709277 1.9435309  1.6696192  0.         0.\n",
      "    1.8035527  0.29440305]\n",
      "   [0.6772367  0.53653395 0.6653875  1.7039522  0.         0.\n",
      "    1.4960648  1.4405928 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Example input data, assuming the input shape is (1, 8, 8, 1)\n",
    "input_data = np.array([\n",
    "    0.0, 0.0, 0.3125, 0.8125, 0.5625, 0.0625, 0.0, 0.0, 0.0, 0.0, \n",
    "    0.8125, 0.9375, 0.625, 0.9375, 0.3125, 0.0, 0.0, 0.1875, 0.9375, 0.125, \n",
    "    0.0, 0.6875, 0.5, 0.0, 0.0, 0.25, 0.75, 0.0, 0.0, 0.5, \n",
    "    0.5, 0.0, 0.0, 0.3125, 0.5, 0.0, 0.0, 0.5625, 0.5, 0.0, \n",
    "    0.0, 0.25, 0.6875, 0.0, 0.0625, 0.75, 0.4375, 0.0, 0.0, 0.125, \n",
    "    0.875, 0.3125, 0.625, 0.75, 0.0, 0.0, 0.0, 0.0, 0.375, 0.8125, \n",
    "    0.625, 0.0, 0.0, 0.0,\n",
    "]).reshape(1, 8, 8, 1).astype(np.float32)\n",
    "\n",
    "# Get the intermediate layer outputs\n",
    "conv_output = conv_model(input_data)\n",
    "print(f\"Output of the convolutional layer: {conv_output.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "def get_data():\n",
    "    np.random.seed(1337)\n",
    "    x_values, y_values = load_digits(return_X_y=True)\n",
    "    x_values /= x_values.max()\n",
    "    # reshape to (8 x 8 x 1)\n",
    "    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n",
    "    # split into train, validation, test\n",
    "    TRAIN_SPLIT = int(0.6 * len(x_values))\n",
    "    TEST_SPLIT = int(0.2 * len(x_values) + TRAIN_SPLIT)\n",
    "    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    return x_train, x_test, x_validate, y_train, y_test, y_validate\n",
    "\n",
    "\n",
    "# Define a representative dataset generator for quantization\n",
    "def representative_dataset():\n",
    "    X_train, X_test, X_validate, y_train, y_test, y_validate = get_data()\n",
    "    for i in range(len(X_train)):\n",
    "        input_data = np.array([X_train[i]], dtype=np.float32)\n",
    "        yield [input_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\srico\\AppData\\Local\\Temp\\tmpl6h1y5wa\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\srico\\AppData\\Local\\Temp\\tmpl6h1y5wa\\assets\n",
      "c:\\Users\\srico\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(intermediate_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # Quantize input\n",
    "converter.inference_output_type = tf.int8  # Quantize output\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model\n",
    "with open('inter_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details:\n",
      "{'name': 'serving_default_conv2d_input:0', 'index': 0, 'shape': array([1, 8, 8, 1]), 'shape_signature': array([-1,  8,  8,  1]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003921568859368563, -128), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Output Details:\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 6, 'shape': array([1, 6, 6, 8]), 'shape_signature': array([-1,  6,  6,  8]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019547035917639732, -128), 'quantization_parameters': {'scales': array([0.01954704], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:3', 'index': 7, 'shape': array([1, 3, 3, 8]), 'shape_signature': array([-1,  3,  3,  8]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019547035917639732, -128), 'quantization_parameters': {'scales': array([0.01954704], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:2', 'index': 8, 'shape': array([ 1, 72]), 'shape_signature': array([-1, 72]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019547035917639732, -128), 'quantization_parameters': {'scales': array([0.01954704], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:1', 'index': 9, 'shape': array([ 1, 10]), 'shape_signature': array([-1, 10]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11720886081457138, 60), 'quantization_parameters': {'scales': array([0.11720886], dtype=float32), 'zero_points': array([60]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Name: serving_default_conv2d_input:0, Index: 0, Shape: [1 8 8 1], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "Name: model/flatten/Const, Index: 1, Shape: [2], Type: <class 'numpy.int32'>, Quantization Parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "Name: model/dense/BiasAdd/ReadVariableOp, Index: 2, Shape: [10], Type: <class 'numpy.int32'>, Quantization Parameters: {'scales': array([0.00024964], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "Name: model/dense/MatMul, Index: 3, Shape: [10 72], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.01277144], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "Name: model/conv2d/BiasAdd/ReadVariableOp, Index: 4, Shape: [8], Type: <class 'numpy.int32'>, Quantization Parameters: {'scales': array([3.6975078e-05, 3.4448829e-05, 3.3599266e-05, 3.5024663e-05,\n",
      "       4.0283394e-05, 3.3538246e-05, 3.1819487e-05, 3.5733367e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "Name: model/conv2d/Conv2D, Index: 5, Shape: [8 3 3 1], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.00942864, 0.00878445, 0.00856781, 0.00893129, 0.01027226,\n",
      "       0.00855225, 0.00811397, 0.00911201], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "Name: StatefulPartitionedCall:0, Index: 6, Shape: [1 6 6 8], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.01954704], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "Name: StatefulPartitionedCall:3, Index: 7, Shape: [1 3 3 8], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.01954704], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "Name: StatefulPartitionedCall:2, Index: 8, Shape: [ 1 72], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.01954704], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "Name: StatefulPartitionedCall:1, Index: 9, Shape: [ 1 10], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([0.11720886], dtype=float32), 'zero_points': array([60]), 'quantized_dimension': 0}\n",
      "Name: , Index: 16, Shape: [1 6 6 9], Type: <class 'numpy.int8'>, Quantization Parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Users\\srico\\Documents\\BEARHW\\Image Classification CNN\\python_scripts\\inter_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Print input details\n",
    "print(\"Input Details:\")\n",
    "for detail in input_details:\n",
    "    print(detail)\n",
    "\n",
    "# Print output details\n",
    "print(\"Output Details:\")\n",
    "for detail in output_details:\n",
    "    print(detail)\n",
    "\n",
    "# Print model layers and their details\n",
    "def print_tensor_details(interpreter):\n",
    "    tensor_details = interpreter.get_tensor_details()\n",
    "    for tensor in tensor_details:\n",
    "        print(f\"Name: {tensor['name']}, Index: {tensor['index']}, Shape: {tensor['shape']}, Type: {tensor['dtype']}, Quantization Parameters: {tensor['quantization_parameters']}\")\n",
    "\n",
    "print_tensor_details(interpreter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input scale: 0.003921568859368563, Input zero point: -128\n",
      "Quantized Input Data:\n",
      "[-128 -128  -48   79   15 -112 -128 -128 -128 -128   79  111   31  111\n",
      "  -48 -128 -128  -80  111  -96 -128   47   -1 -128 -128  -64   63 -128\n",
      " -128   -1   -1 -128 -128  -48   -1 -128 -128   15   -1 -128 -128  -64\n",
      "   47 -128 -112   63  -16 -128 -128  -96   95  -48   31   63 -128 -128\n",
      " -128 -128  -32   79   31 -128 -128 -128]\n",
      "Quantized Output Data:\n",
      "[ -79 -128  -66 -128  -33  -70 -128 -128   16 -128   -8 -119  -16  -70\n",
      " -112 -128   16 -111   26  -39  -90 -128  -14 -116  -11 -128    8  -52\n",
      "  -72 -128  -33 -100    3 -128  -58 -123  -52 -112  -77 -128  -55 -115\n",
      " -102 -128  -76 -128  -59 -128  -62 -120  -40 -122  -24  -54 -128 -123\n",
      "   23 -106  -13  -60  -76 -115  -66 -128  -41  -42  -35    1 -120 -128\n",
      "   10  -59  -59  -71  -22  -25  -74 -113  -69  -40   10 -128  -10  -71\n",
      "  -77 -128  -67 -122  -28 -116  -80  -86  -91 -128  -41 -112  -55 -105\n",
      "  -38  -97  -41  -65 -119 -109   -4 -121  -40  -73 -116 -128  -54 -128\n",
      "  -95  -82 -107  -71 -114 -128  -49  -71  -99  -91  -76 -102  -67  -69\n",
      " -125  -96  -13 -128  -28 -100  -61 -107  -94 -128  -25 -109  -73  -91\n",
      "  -97 -128  -46 -125  -53 -111  -48 -105  -53  -76 -113 -127  -17 -122\n",
      "  -67  -95  -99 -128  -62 -128 -100  -73 -116 -102 -105 -128  -67  -95\n",
      "  -93 -108  -76 -126  -56  -70 -128 -122   -7 -128  -38 -120  -44  -98\n",
      " -101 -128  -26 -103  -70  -98  -96 -128  -42 -128  -56 -126  -40 -115\n",
      "  -53  -81 -112 -128    1 -128  -72 -127  -70 -128  -77 -128  -63  -90\n",
      " -104 -128  -53 -128  -54 -128  -47 -112  -65 -128   -4  -72 -121 -128\n",
      "    6 -113  -29 -116  -57 -106  -81 -128  -52  -95  -65  -66 -124 -128\n",
      "  -30 -106  -82 -105  -38  -86  -69  -71 -120  -88    4 -128  -27 -110\n",
      "  -79 -121  -78 -128  -10 -128  -63 -128   -9 -126  -59 -128  -15 -106\n",
      "  -31 -126  -28  -76  -90 -128  -28  -95  -29  -43 -128 -128  -36 -113\n",
      "  -93 -100  -94  -41 -128 -128  -51  -54]\n",
      "Output scale: 0.019547035917639732, Output zero point: -128\n",
      "Dequantized Output Data:\n",
      "[ 0.95780476  0.          1.21191623  0.          1.85696841  1.13372808\n",
      "  0.          0.         -2.18926802  0.          2.34564431  0.17592332\n",
      "  2.18926802  1.13372808  0.31275257  0.         -2.18926802  0.33229961\n",
      " -1.99379766  1.7396862   0.74278736  0.          2.22836209  0.23456443\n",
      "  2.2870032   0.         -2.34564431  1.48557473  1.09463401  0.\n",
      "  1.85696841  0.54731701 -2.44337949  0.          1.36829251  0.09773518\n",
      "  1.48557473  0.31275257  0.99689883  0.          1.42693362  0.25411147\n",
      "  0.50822293  0.          1.01644587  0.          1.34874548  0.\n",
      "  1.29010437  0.15637629  1.72013916  0.11728222  2.03289174  1.44648066\n",
      "  0.          0.09773518 -2.05243877  0.43003479  2.24790913  1.32919844\n",
      "  1.01644587  0.25411147  1.21191623  0.          1.70059212  1.68104509\n",
      "  1.81787434 -2.48247356  0.15637629  0.         -2.30655024  1.34874548\n",
      "  1.34874548  1.11418105  2.07198581  2.0133447   1.05553994  0.29320554\n",
      "  1.15327512  1.72013916 -2.30655024  0.          2.30655024  1.11418105\n",
      "  0.99689883  0.          1.19236919  0.11728222  1.95470359  0.23456443\n",
      "  0.93825772  0.82097551  0.72324033  0.          1.70059212  0.31275257\n",
      "  1.42693362  0.44958183  1.75923323  0.60595811  1.70059212  1.23146326\n",
      "  0.17592332  0.37139368  2.42383245  0.13682925  1.72013916  1.07508698\n",
      "  0.23456443  0.          1.44648066  0.          0.64505219  0.89916365\n",
      "  0.41048775  1.11418105  0.2736585   0.          1.54421584  1.11418105\n",
      "  0.56686404  0.72324033  1.01644587  0.50822293  1.19236919  1.15327512\n",
      "  0.05864111  0.62550515  2.24790913  0.          1.95470359  0.54731701\n",
      "  1.30965141  0.41048775  0.66459922  0.          2.0133447   0.37139368\n",
      "  1.07508698  0.72324033  0.60595811  0.          1.60285695  0.05864111\n",
      "  1.46602769  0.33229961  1.56376287  0.44958183  1.46602769  1.01644587\n",
      "  0.29320554  0.01954704  2.16972099  0.11728222  1.19236919  0.64505219\n",
      "  0.56686404  0.          1.29010437  0.          0.54731701  1.07508698\n",
      "  0.23456443  0.50822293  0.44958183  0.          1.19236919  0.64505219\n",
      "  0.68414626  0.39094072  1.01644587  0.03909407  1.40738659  1.13372808\n",
      "  0.          0.11728222  2.36519135  0.          1.75923323  0.15637629\n",
      "  1.64195102  0.58641108  0.52776997  0.          1.99379766  0.4886759\n",
      "  1.13372808  0.58641108  0.62550515  0.          1.68104509  0.\n",
      "  1.40738659  0.03909407  1.72013916  0.25411147  1.46602769  0.91871069\n",
      "  0.31275257  0.         -2.48247356  0.          1.09463401  0.01954704\n",
      "  1.13372808  0.          0.99689883  0.          1.27055733  0.74278736\n",
      "  0.46912886  0.          1.46602769  0.          1.44648066  0.\n",
      "  1.58330991  0.31275257  1.23146326  0.          2.42383245  1.09463401\n",
      "  0.13682925  0.         -2.38473838  0.29320554  1.93515656  0.23456443\n",
      "  1.38783955  0.43003479  0.91871069  0.          1.48557473  0.64505219\n",
      "  1.23146326  1.21191623  0.07818814  0.          1.91560952  0.43003479\n",
      "  0.89916365  0.44958183  1.75923323  0.82097551  1.15327512  1.11418105\n",
      "  0.15637629  0.78188144 -2.42383245  0.          1.97425063  0.35184665\n",
      "  0.95780476  0.13682925  0.9773518   0.          2.30655024  0.\n",
      "  1.27055733  0.          2.32609727  0.03909407  1.34874548  0.\n",
      "  2.20881506  0.43003479  1.89606248  0.03909407  1.95470359  1.01644587\n",
      "  0.74278736  0.          1.95470359  0.64505219  1.93515656  1.66149805\n",
      "  0.          0.          1.7983273   0.29320554  0.68414626  0.54731701\n",
      "  0.66459922  1.70059212  0.          0.          1.50512177  1.44648066]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Users\\srico\\Documents\\BEARHW\\Image Classification CNN\\python_scripts\\inter_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "print(f\"Input scale: {input_scale}, Input zero point: {input_zero_point}\")\n",
    "\n",
    "# Quantize the float input data\n",
    "input_data = np.array([\n",
    "    0.0, 0.0, 0.3125, 0.8125, 0.5625, 0.0625, 0.0, 0.0, 0.0, 0.0, \n",
    "    0.8125, 0.9375, 0.625, 0.9375, 0.3125, 0.0, 0.0, 0.1875, 0.9375, 0.125, \n",
    "    0.0, 0.6875, 0.5, 0.0, 0.0, 0.25, 0.75, 0.0, 0.0, 0.5, \n",
    "    0.5, 0.0, 0.0, 0.3125, 0.5, 0.0, 0.0, 0.5625, 0.5, 0.0, \n",
    "    0.0, 0.25, 0.6875, 0.0, 0.0625, 0.75, 0.4375, 0.0, 0.0, 0.125, \n",
    "    0.875, 0.3125, 0.625, 0.75, 0.0, 0.0, 0.0, 0.0, 0.375, 0.8125, \n",
    "    0.625, 0.0, 0.0, 0.0\n",
    "]).reshape(1, 8, 8, 1).astype(np.float32)  # Replace with actual input data\n",
    "quantized_input_data = np.round(input_data / input_scale) + input_zero_point\n",
    "quantized_input_data = quantized_input_data.astype(np.int8)\n",
    "\n",
    "print(\"Quantized Input Data:\")\n",
    "print(np.array(quantized_input_data).flatten())\n",
    "\n",
    "# Set the input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], quantized_input_data)\n",
    "\n",
    "# Run the model (invoke the interpreter)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Print the quantized output data\n",
    "print(\"Quantized Output Data:\")\n",
    "output_data = np.array(output_data).flatten()\n",
    "print(output_data)\n",
    "\n",
    "# Extract output quantization parameters\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "print(f\"Output scale: {output_scale}, Output zero point: {output_zero_point}\")\n",
    "\n",
    "# Dequantize the output data\n",
    "dequantized_output_data = (output_data - output_zero_point) * output_scale\n",
    "\n",
    "# Print the dequantized output data\n",
    "print(\"Dequantized Output Data:\")\n",
    "print(dequantized_output_data)\n",
    "\n",
    "# Print biases and filter data\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "\n",
    "# for tensor in tensor_details:\n",
    "#     if 'bias' in tensor['name'] or 'BiasAdd' in tensor['name']:\n",
    "#         print(f\"Biases for {tensor['name']}:\")\n",
    "#         tensor_index = tensor['index']\n",
    "#         bias_data = interpreter.tensor(tensor_index)()\n",
    "#         print(bias_data.flatten())\n",
    "#     if 'conv' in tensor['name'] or 'Conv2D' in tensor['name'] or 'filter' in tensor['name']:\n",
    "#         print(f\"Filters for {tensor['name']}:\")\n",
    "#         tensor_index = tensor['index']\n",
    "#         filter_data = interpreter.tensor(tensor_index)()\n",
    "#         print(filter_data.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input scale: 0.003921568859368563, Input zero point: -128\n",
      "Output scale: 0.019547035917639732, Output zero point: -128\n",
      "Effective Scales for model_1/conv2d/BiasAdd/ReadVariableOp: [7.4180207e-06 6.9111993e-06 6.7407577e-06 7.0267238e-06 8.0817417e-06\n",
      " 6.7285159e-06 6.3836942e-06 7.1689055e-06]\n",
      "Multipliers for model_1/conv2d/BiasAdd/ReadVariableOp: [2087987200 1945329664 1897354624 1977846912 1137404032 1893908864\n",
      " 1796850176 2017867520]\n",
      "Shifts for model_1/conv2d/BiasAdd/ReadVariableOp: [-17 -17 -17 -17 -16 -17 -17 -17]\n",
      "Effective Scales for model_1/conv2d/Conv2D: [0.0018916  0.00176236 0.00171889 0.00179181 0.00206084 0.00171577\n",
      " 0.00162784 0.00182807]\n",
      "Multipliers for model_1/conv2d/Conv2D: [2079830784 1937730560 1889943040 1970120960 1132961024 1886510720\n",
      " 1789831296 2009985152]\n",
      "Shifts for model_1/conv2d/Conv2D: [-9 -9 -9 -9 -8 -9 -9 -9]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate multiplier and shift\n",
    "def calculate_multiplier_shift(effective_scale):\n",
    "    significand, exponent = np.frexp(effective_scale)\n",
    "    significand_q31 = np.round(significand * (1 << 31)).astype(np.int64)\n",
    "    return significand_q31, exponent\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Users\\srico\\Documents\\BEARHW\\Image Classification CNN\\python_scripts\\conv_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Extract input quantization parameters\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "print(f\"Input scale: {input_scale}, Input zero point: {input_zero_point}\")\n",
    "\n",
    "# Extract output quantization parameters\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "print(f\"Output scale: {output_scale}, Output zero point: {output_zero_point}\")\n",
    "\n",
    "# Function to check if a layer is a convolutional layer\n",
    "def is_convolutional_layer(tensor_name):\n",
    "    return ('conv' in tensor_name.lower() or 'conv2d' in tensor_name.lower()) and 'input' not in tensor_name.lower()\n",
    "\n",
    "# Print biases and filter data, and calculate multipliers and shifts\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "\n",
    "conv_weight_tensors = [tensor for tensor in tensor_details if is_convolutional_layer(tensor['name'])]\n",
    "if conv_weight_tensors:\n",
    "    for weight_tensor in conv_weight_tensors:\n",
    "        weight_scales = weight_tensor['quantization_parameters']['scales']\n",
    "        effective_scales = input_scale * weight_scales / output_scale\n",
    "\n",
    "        # Calculate the multiplier and shift for each channel\n",
    "        multipliers, shifts = calculate_multiplier_shift(effective_scales)\n",
    "\n",
    "        print(f\"Effective Scales for {weight_tensor['name']}: {effective_scales}\")\n",
    "        print(f\"Multipliers for {weight_tensor['name']}: {multipliers}\")\n",
    "        print(f\"Shifts for {weight_tensor['name']}: {shifts}\")\n",
    "else:\n",
    "    print(\"No convolutional layer found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input scale: 0.003921568859368563, Input zero point: -128\n",
      "Output scale: 0.11720886081457138, Output zero point: 60\n",
      "Quantized Input Data:\n",
      "[-128 -128  -16   -1   79  127  111 -112 -128 -128  -16  -16  -64   47\n",
      "   63 -128 -128 -128 -128 -128   -1   79 -112 -128 -128  -64   -1   -1\n",
      "  111  111  -32 -128 -128  -96   47  111  111  -64 -128 -128 -128 -128\n",
      " -128  127  -48 -128 -128 -128 -128 -128   15  111 -112 -128 -128 -128\n",
      " -128 -128   79  -48 -128 -128 -128 -128]\n",
      "Layer: serving_default_conv2d_input:0\n",
      "[[[[-128]\n",
      "   [-128]\n",
      "   [ -16]\n",
      "   [  -1]\n",
      "   [  79]\n",
      "   [ 127]\n",
      "   [ 111]\n",
      "   [-112]]\n",
      "\n",
      "  [[-128]\n",
      "   [-128]\n",
      "   [ -16]\n",
      "   [ -16]\n",
      "   [ -64]\n",
      "   [  47]\n",
      "   [  63]\n",
      "   [-128]]\n",
      "\n",
      "  [[-128]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [  -1]\n",
      "   [  79]\n",
      "   [-112]\n",
      "   [-128]]\n",
      "\n",
      "  [[-128]\n",
      "   [ -64]\n",
      "   [  -1]\n",
      "   [  -1]\n",
      "   [ 111]\n",
      "   [ 111]\n",
      "   [ -32]\n",
      "   [-128]]\n",
      "\n",
      "  [[-128]\n",
      "   [ -96]\n",
      "   [  47]\n",
      "   [ 111]\n",
      "   [ 111]\n",
      "   [ -64]\n",
      "   [-128]\n",
      "   [-128]]\n",
      "\n",
      "  [[-128]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [ 127]\n",
      "   [ -48]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [-128]]\n",
      "\n",
      "  [[-128]\n",
      "   [-128]\n",
      "   [  15]\n",
      "   [ 111]\n",
      "   [-112]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [-128]]\n",
      "\n",
      "  [[-128]\n",
      "   [-128]\n",
      "   [  79]\n",
      "   [ -48]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [-128]\n",
      "   [-128]]]]\n",
      "Layer: sequential/flatten/Const\n",
      "[-1 72]\n",
      "Layer: sequential/dense/BiasAdd/ReadVariableOp\n",
      "[ 113  208   40   34 -297  -45  -50 -219  174  -12]\n",
      "Layer: sequential/dense/MatMul\n",
      "[[  18  -71   21  -18   22  -14    2  -83  -27   45   32   41  -30    4\n",
      "   -12   33   11  -22    4  -45   15  -77  -10  -53    2  -60   -7  -26\n",
      "    -7   -3   33 -109  -79   37  -38   -3  -31   70   13   22  -12  -41\n",
      "    -4  -33   -3    3  -23  -28   25  -30    8  -12  -16   14   25   23\n",
      "   -15  -43  -15  -63    9   54   -3  -10   14  -10   28   35   23    5\n",
      "   -10   16]\n",
      " [ -28    4   -6 -112   31  -25 -100  -36   34  -76    6  -88    7   25\n",
      "    -3  -66  -17    9   19    1  -30   13    5   -8  -28  -20   11    1\n",
      "     8   19   -7   15   27  -78   44    4    5  -86   22  -28   13   25\n",
      "   -24  -34  -51   24    3   -5  -33   15   14  -25    6   -8  -46  -37\n",
      "    39  -93    7  -18   10   18   -5  -25   11   29  -24  -72   -8   31\n",
      "     8  -22]\n",
      " [ -13   25   -2   40  -19   -8    2   40   -8  -65   11   11  -15   28\n",
      "     4    9  -20    9  -13  -21   17   25   31  -11  -44   13  -51  -11\n",
      "     6  -55   -1   24    9   -7  -44  -44    1   39  -28  -19  -42  -41\n",
      "     3   39  -44   26   -2   47   -9  -59   30  -15   23    4   -2  -15\n",
      "    30  -53   27  -18   15  -32   30   -3   -4   16  -27  -46   68   28\n",
      "    -1  -67]\n",
      " [ -20   42   -6   68  -40   16   26   18  -13  -12   -9   21   -3   40\n",
      "   -25  -15    5   -8  -17   41  -35  -33   28   42  -57   23  -36  -13\n",
      "   -50   -9  -47   -6   16   -3   12  -21   -8   76  -10  -17    7   37\n",
      "    -2  -48   39   28   -2  -40   -3  -19  -37  -23    7    0  -28   -5\n",
      "   -16   52    9  -35   14   -7  -36  -12    9  -11   20   22   26  -62\n",
      "    10  -20]\n",
      " [  12  -54  -17 -122   17  -34  -43 -102  -22  -69  -28  -21    2   48\n",
      "     7  -23  -15  -11  -61  -54   24   54  -34  -17   34  -64   -1  -15\n",
      "    24    6   40  -17   14  -48   -5  -40   35  -47    8  -60   -3  -14\n",
      "    20    2   27   -1   18    4   -4   11    2   52  -34  -43   33   33\n",
      "     1  -34    6   30  -26  -33  -32  -16  -33   15   16   50  -73   10\n",
      "    35   34]\n",
      " [  43  -46    4  -27   -9   16   12  -73  -15   58  -10   24   -5  -97\n",
      "     4   27  -44   28   14   67  -43   11    8   39   -1   -1   27   38\n",
      "   -30  -11   29   23    2   28   13   43  -54  -60  -29   33   -4   -2\n",
      "   -24  -53    8  -12  -21  -74   -1   -3  -35    8   26  -38  -10  -61\n",
      "   -21   -2  -14    0  -20   20  -19  -18  -27    6  -22   31  -25  -14\n",
      "    19   28]\n",
      " [ -12  -70    7  -77   18  -22  -48  -84  -18   32  -13  -15  -37  -12\n",
      "    18   39  -47    9  -38  -19  -36   24  -37    1   32  -97   30  -43\n",
      "    10   20   10 -127    0   19   15  -21  -15  -39   31   34    9   15\n",
      "   -14  -56   18   -9  -24  -75    9   10   12    2   -8   12    1   28\n",
      "     9   37    0    1    9  -56   12    7    4  -29   16  -21   40  -58\n",
      "   -27  -54]\n",
      " [ -21   33   12   31  -10   13  -13   11  -17   10   13   11  -35  -25\n",
      "   -16   15    4    6   41   -8    9  -24   23    0  -22  -16  -25  -24\n",
      "    18   33  -16   -9    1  -36  -11  -27   23   45  -10  -14   12  -39\n",
      "    38   26   43  -17    0   24  -72    7  -21  -18   14   -1  -12  -16\n",
      "    -7   15   12   21  -52  -17    3   61  -61   -4  -17   34 -126   42\n",
      "     2   41]\n",
      " [  22  -28   -6  -28  -18   17    5    6  -28   33  -24  -21   35  -36\n",
      "    17  -64    9    5   17  -10   -5  -40  -16   29  -24   24   12  -59\n",
      "    23  -23  -30    8   -9  -25   15   20   19  -69    3  -78  -28   25\n",
      "    -2   35    4   -8    5   30   -7  -34  -18  -24    0   32   -7   35\n",
      "   -29  -38   10   22   17  -62   29  -14    7    5   26  -47   -3  -74\n",
      "     3  -17]\n",
      " [  15  -15    3  -25  -19   12   20  -18  -18  -20  -24  -36   11    7\n",
      "     5  -53   49   -4   -1  -53    5  -40    3  -31  -11   39   23   39\n",
      "   -38  -16  -10   42   -3    1    8   18   11    5  -14   51   24  -32\n",
      "    12   56  -40 -126   13    9  -19   16  -37    2    3   17  -39  -11\n",
      "   -19   32  -57  -14    9   16  -47    7  -24  -22  -16   11   -4    7\n",
      "     1  -14]]\n",
      "Layer: sequential/conv2d/BiasAdd/ReadVariableOp\n",
      "[-1482 17051 -1396  7127  1298 19318 -1435 16603]\n",
      "Layer: sequential/conv2d/Conv2D\n",
      "[[[[  24]\n",
      "   [  85]\n",
      "   [  22]]\n",
      "\n",
      "  [[  30]\n",
      "   [ 127]\n",
      "   [  31]]\n",
      "\n",
      "  [[  39]\n",
      "   [ 121]\n",
      "   [  56]]]\n",
      "\n",
      "\n",
      " [[[  21]\n",
      "   [  30]\n",
      "   [ 109]]\n",
      "\n",
      "  [[ -46]\n",
      "   [-127]\n",
      "   [ -77]]\n",
      "\n",
      "  [[  94]\n",
      "   [ -41]\n",
      "   [ -42]]]\n",
      "\n",
      "\n",
      " [[[   3]\n",
      "   [ 125]\n",
      "   [  64]]\n",
      "\n",
      "  [[  35]\n",
      "   [ 103]\n",
      "   [ 127]]\n",
      "\n",
      "  [[  18]\n",
      "   [ -24]\n",
      "   [  29]]]\n",
      "\n",
      "\n",
      " [[[  64]\n",
      "   [ 127]\n",
      "   [ 104]]\n",
      "\n",
      "  [[  79]\n",
      "   [  16]\n",
      "   [ -11]]\n",
      "\n",
      "  [[ -76]\n",
      "   [-119]\n",
      "   [ -82]]]\n",
      "\n",
      "\n",
      " [[[   2]\n",
      "   [ -57]\n",
      "   [  41]]\n",
      "\n",
      "  [[   8]\n",
      "   [ -16]\n",
      "   [  73]]\n",
      "\n",
      "  [[  40]\n",
      "   [ 127]\n",
      "   [  84]]]\n",
      "\n",
      "\n",
      " [[[ -42]\n",
      "   [-127]\n",
      "   [  53]]\n",
      "\n",
      "  [[ -76]\n",
      "   [  41]\n",
      "   [  48]]\n",
      "\n",
      "  [[ -15]\n",
      "   [ -24]\n",
      "   [   6]]]\n",
      "\n",
      "\n",
      " [[[  57]\n",
      "   [ 119]\n",
      "   [  14]]\n",
      "\n",
      "  [[ 127]\n",
      "   [  11]\n",
      "   [ -27]]\n",
      "\n",
      "  [[  67]\n",
      "   [  -2]\n",
      "   [  18]]]\n",
      "\n",
      "\n",
      " [[[  90]\n",
      "   [  21]\n",
      "   [  77]]\n",
      "\n",
      "  [[  22]\n",
      "   [ -57]\n",
      "   [  20]]\n",
      "\n",
      "  [[ -95]\n",
      "   [-121]\n",
      "   [-127]]]]\n",
      "Layer: sequential/max_pooling2d/MaxPool\n",
      "[[[[ -66   -1   15  -11  -29  -29  -68   81]\n",
      "   [  37   29    4  -36   24  -86  -50  -80]\n",
      "   [  49  -69   24  -30  -33 -128    2  -97]]\n",
      "\n",
      "  [[ -17 -101    9  -80  -20  -79  -90  -74]\n",
      "   [  56  -80   23  -14   38  -83   12 -109]\n",
      "   [  18  -78   -1    9 -101 -128    0  -47]]\n",
      "\n",
      "  [[ -16  -73   -5  -96   -5  -50  -93 -105]\n",
      "   [  58  -64    6  -19  -52 -127   20  -59]\n",
      "   [-104  -90 -110  -64 -125  -95  -77  -55]]]]\n",
      "Layer: sequential/flatten/Reshape\n",
      "[[ -61  -78  -48  -65  -69  -75  -96  -78   24  -99    4  -36   24  -86\n",
      "   -50  -80   49  -69   24  -30  -33 -128    2  -97  -17 -101    9  -80\n",
      "   -20  -79  -90  -74   56  -80   23  -14   38  -83   12 -109   18  -78\n",
      "    -1    9 -101 -128    0  -47  -16  -73   -5  -96   -5  -50  -93 -105\n",
      "    58  -64    6  -19  -52 -127   20  -59 -104  -90 -110  -64 -125  -95\n",
      "   -77  -55]]\n",
      "Layer: StatefulPartitionedCall:0\n",
      "[[-66  -1  15 -11 -29 -29 -68  81  37  29]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=r\"C:\\Users\\srico\\Documents\\BEARHW\\Image Classification CNN\\models\\quantized_CNN_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to get all layer outputs\n",
    "# Function to get all layer outputs\n",
    "def get_all_intermediate_outputs(interpreter, input_data):\n",
    "    # Set the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Run the interpreter\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get outputs for all layers\n",
    "    all_outputs = {}\n",
    "    tensor_details = interpreter.get_tensor_details()\n",
    "    \n",
    "    for details in tensor_details:\n",
    "        try:\n",
    "            output_data = interpreter.get_tensor(details['index'])\n",
    "            all_outputs[details['name']] = output_data\n",
    "        except ValueError:\n",
    "            # Skip tensors that cannot be retrieved\n",
    "            continue\n",
    "        \n",
    "    return all_outputs\n",
    "# Prepare the input data as per your model's requirements\n",
    "input_data = np.array([\n",
    "    0.0, 0.0, 0.4375, 0.5, 0.8125, 1.0, 0.9375, 0.0625, 0.0, 0.0, \n",
    "    0.4375, 0.4375, 0.25, 0.6875, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "    0.5, 0.8125, 0.0625, 0.0, 0.0, 0.25, 0.5, 0.5, 0.9375, 0.9375, \n",
    "    0.375, 0.0, 0.0, 0.125, 0.6875, 0.9375, 0.9375, 0.25, 0.0, 0.0, \n",
    "    0.0, 0.0, 0.0, 1.0, 0.3125, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "    0.5625, 0.9375, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8125, 0.3125, \n",
    "    0.0, 0.0, 0.0, 0.0\n",
    "]).reshape(1, 8, 8, 1).astype(np.float32)  # Replace with actual input data\n",
    "\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "print(f\"Input scale: {input_scale}, Input zero point: {input_zero_point}\")\n",
    "\n",
    "# Extract output quantization parameters\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "print(f\"Output scale: {output_scale}, Output zero point: {output_zero_point}\")\n",
    "\n",
    "quantized_input_data = np.round(input_data / input_scale) + input_zero_point\n",
    "quantized_input_data = quantized_input_data.astype(np.int8)\n",
    "\n",
    "print(\"Quantized Input Data:\")\n",
    "print(np.array(quantized_input_data).flatten())\n",
    "\n",
    "# Get all intermediate layer outputs\n",
    "intermediate_outputs = get_all_intermediate_outputs(interpreter, quantized_input_data)\n",
    "\n",
    "# Print all intermediate layer outputs\n",
    "for layer_name, output_data in intermediate_outputs.items():\n",
    "    print(f\"Layer: {layer_name}\")\n",
    "    print(output_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
